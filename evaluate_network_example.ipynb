{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Jaime Tierney, Adam Luchies, and Brett Byram\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the license at\n",
    "\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and \n",
    "# limitations under the License.\n",
    "\n",
    "# INSTALL NECESSARY PACKAGES PRIOR TO RUNNING THIS NOTEBOOK\n",
    "# pytorch\n",
    "# jupyter \n",
    "# numpy\n",
    "# scipy\n",
    "# matplotlib\n",
    "# pandas\n",
    "# h5py\n",
    "\n",
    "# IMPORT PYTHON PACKAGES\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from scipy.signal import hilbert\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# IMPORT FUNCTIONS FROM PROVIDED SOURCE CODE\n",
    "sys.path.insert(0,'src')\n",
    "from utils import read_model_params\n",
    "from model import FullyConnectedNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFY PATH TO MODEL (THIS IS ALSO OUTPUT PATH)\n",
    "model_path = 'models/model_1/k_8/'\n",
    "\n",
    "# LOAD IN MODEL PARAMS\n",
    "model_params = read_model_params(model_path+'model_params.txt')\n",
    "\n",
    "# PROVIDE TEST DATA FILE INFO\n",
    "test_data_path = 'test_data/'\n",
    "test_data_name = 'chandat_phantom_5mm_70mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFY CUDA AVAILABILITY\n",
    "print('torch.cuda.is_available(): ' + str(torch.cuda.is_available()))\n",
    "if model_params['cuda'] and torch.cuda.is_available():\n",
    "    print('Using ' + str(torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    print('Not using CUDA')\n",
    "    model_params['cuda']=False\n",
    "device = torch.device(\"cuda:0\" if model_params['cuda'] else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IN THE TEST DATA AND REFORMAT FOR NETWORK PROCESSING\n",
    "\n",
    "# load in delayed RF channel data\n",
    "f = h5py.File(os.path.join(test_data_path,test_data_name+'.mat'),'r')\n",
    "rf_data = np.asarray(f['chandat'])\n",
    "f.close()\n",
    "\n",
    "# get dimension info\n",
    "[N_beams,N_elements,N_depths] = rf_data.shape\n",
    "\n",
    "# get analytic data\n",
    "analytic_data = hilbert(rf_data,axis=2)\n",
    "del rf_data\n",
    "\n",
    "# switch depth and channel axes\n",
    "analytic_data = np.moveaxis(analytic_data,1,2)\n",
    "\n",
    "# concatenate real and imaginary components into data variable\n",
    "data_real = np.real(analytic_data)\n",
    "data_imag = np.imag(analytic_data)\n",
    "data = np.concatenate([data_real,data_imag],axis=2)\n",
    "del analytic_data\n",
    "\n",
    "# get conventional DAS B-mode data\n",
    "env = np.sqrt(np.power(np.sum(data_real,axis=2),2)+\n",
    "              np.power(np.sum(data_imag,axis=2),2))\n",
    "bmode = 20*np.log10(env)\n",
    "del data_real, data_imag\n",
    "\n",
    "# reshape data to flatten depth and beam axes\n",
    "data = np.reshape(data,[N_beams*N_depths,2*N_elements])\n",
    "\n",
    "# normalize data by L1 norm\n",
    "data_norm = np.linalg.norm(data,ord=np.inf,axis=1)\n",
    "data = data / data_norm[:,np.newaxis]\n",
    "\n",
    "# load data into pytorch and onto gpu\n",
    "data = torch.from_numpy(data).float()\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASS TEST DATA THROUGH NETWORK\n",
    "\n",
    "# start timer\n",
    "t0 = time.time()\n",
    "\n",
    "# load the model\n",
    "model = FullyConnectedNet(input_dim=model_params['input_dim'],\n",
    "                          output_dim=model_params['output_dim'],\n",
    "                          layer_width=model_params['layer_width'],\n",
    "                          dropout=model_params['dropout'],\n",
    "                          dropout_input=model_params['dropout_input'],\n",
    "                          num_hidden=model_params['num_hidden'],\n",
    "                          starting_weights=None,\n",
    "                          batch_norm_enable=model_params['batch_norm_enable'])\n",
    "print('Loading weights from: ' + str(os.path.join(model_params['save_dir'], 'model.dat')))\n",
    "model.load_state_dict(torch.load(os.path.join(model_params['save_dir'], \n",
    "                          'model.dat'), map_location='cpu'))\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "# process test data with the model\n",
    "with torch.set_grad_enabled(False):\n",
    "    data_dnn = model(data).to('cpu').data.numpy()\n",
    "    \n",
    "# stop timer\n",
    "print('Processing time: {:.2f}'.format(time.time()-t0))\n",
    "\n",
    "# clear the model and input data\n",
    "del model, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFORMAT PROCESSED TEST DATA \n",
    "\n",
    "# scale back\n",
    "data_dnn = data_dnn * data_norm[:,np.newaxis]\n",
    "\n",
    "# unflatten depth and beam axes\n",
    "data_dnn = np.reshape(data_dnn,[N_beams,N_depths,2*N_elements])\n",
    "\n",
    "# split up real and imaginary\n",
    "data_dnn_real = data_dnn[:,:,0:N_elements]\n",
    "data_dnn_imag = data_dnn[:,:,N_elements:2*N_elements]\n",
    "\n",
    "# get DNN beamformer B-mode data\n",
    "env_dnn = np.sqrt(np.power(np.sum(data_dnn_real,axis=2),2)+\n",
    "                  np.power(np.sum(data_dnn_imag,axis=2),2))\n",
    "bmode_dnn = 20*np.log10(env_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE IMAGES AND COMPUTE IMAGE QUALITY METRICS\n",
    "\n",
    "# load in params file\n",
    "f = h5py.File(os.path.join(test_data_path,test_data_name+'_params.mat'),'r')\n",
    "beam_position_x = np.asarray(f['beam_position_x'])\n",
    "t = np.asarray(f['t'])\n",
    "fs = np.asarray(f['fs'])\n",
    "c = np.asarray(f['c'])\n",
    "mask_in = np.asarray(f['mask_in'])\n",
    "mask_out = np.asarray(f['mask_out'])\n",
    "f.close()\n",
    "depths = t/fs*c/2\n",
    "\n",
    "# make DAS image\n",
    "bmode_scaled = bmode - np.max(bmode)\n",
    "fig,axs = plt.subplots(nrows=1,ncols=2,sharey=True)\n",
    "das_img=axs[0].imshow(np.moveaxis(bmode_scaled,0,1),cmap='gray',\n",
    "                      aspect='equal',vmin=-60,vmax=0,\n",
    "                      extent=[beam_position_x[0][0]*1000,\n",
    "                              beam_position_x[-1][0]*1000,\n",
    "                              depths[0][-1]*1000,\n",
    "                              depths[0][0]*1000])\n",
    "axs[0].set_title('DAS')\n",
    "axs[0].set_ylabel('Depth (mm)')\n",
    "axs[0].set_xlabel('Lateral Pos. (mm)')\n",
    "fig.colorbar(das_img,ax=axs[0])\n",
    "\n",
    "# make DNN image\n",
    "bmode_dnn_scaled = bmode_dnn - np.max(bmode_dnn)\n",
    "dnn_img=axs[1].imshow(np.moveaxis(bmode_dnn_scaled,0,1),cmap='gray',\n",
    "                      aspect='equal',vmin=-60,vmax=0,\n",
    "                      extent=[beam_position_x[0][0]*1000,\n",
    "                              beam_position_x[-1][0]*1000,\n",
    "                              depths[0][-1]*1000,\n",
    "                              depths[0][0]*1000])\n",
    "axs[1].set_title('DNN')\n",
    "axs[1].set_xlabel('Lateral Pos. (mm)')\n",
    "\n",
    "# add colorbar and save figure\n",
    "fig.colorbar(dnn_img,ax=axs[1])\n",
    "fig.savefig(os.path.join(model_path,test_data_name+'_result.png'))\n",
    "\n",
    "# find indicies corresponding to inside and outside of lesion\n",
    "idx_in = np.where(mask_in==1)\n",
    "idx_out = np.where(mask_out==1)\n",
    "\n",
    "# compute mean and variance for DAS\n",
    "mean_in = np.mean(env[idx_in])\n",
    "mean_out = np.mean(env[idx_out])\n",
    "var_in = np.var(env[idx_in])\n",
    "var_out = np.var(env[idx_out])\n",
    "\n",
    "# compute mean and variance for DNN\n",
    "mean_in_dnn = np.mean(env_dnn[idx_in])\n",
    "mean_out_dnn = np.mean(env_dnn[idx_out])\n",
    "var_in_dnn = np.var(env_dnn[idx_in])\n",
    "var_out_dnn = np.var(env_dnn[idx_out])\n",
    "\n",
    "# compute image quality metrics\n",
    "CNR = 20*np.log10(np.abs(mean_in-mean_out)/np.sqrt(var_in+var_out))\n",
    "CNR_DNN = 20*np.log10(np.abs(mean_in_dnn-mean_out_dnn)/\n",
    "                      np.sqrt(var_in_dnn+var_out_dnn))\n",
    "CR = -20*np.log10(np.abs(mean_in/mean_out))\n",
    "CR_DNN = -20*np.log10(np.abs(mean_in_dnn/mean_out_dnn))\n",
    "print('CNR DAS: {:.2f}'.format(CNR))\n",
    "print('CNR DNN: {:.2f}'.format(CNR_DNN))\n",
    "print('CR DAS: {:.2f}'.format(CR))\n",
    "print('CR DNN: {:.2f}'.format(CR_DNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
