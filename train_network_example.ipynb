{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Jaime Tierney, Adam Luchies, and Brett Byram\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the license at\n",
    "\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and \n",
    "# limitations under the License.\n",
    "\n",
    "# INSTALL NECESSARY PACKAGES PRIOR TO RUNNING THIS NOTEBOOK (SEE README FOR INSTRUCTIONS)\n",
    "# pytorch\n",
    "# jupyter \n",
    "# numpy\n",
    "# scipy\n",
    "# h5py\n",
    "# matplotlib\n",
    "# pandas\n",
    "# livelossplot \n",
    "\n",
    "# IMPORT PYTHON PACKAGES\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# IMPORT FUNCTIONS FROM PROVIDED SOURCE CODE\n",
    "sys.path.insert(0,'src')\n",
    "from utils import save_model_params, ensure_dir\n",
    "from dataloader import ApertureDataset\n",
    "from model import FullyConnectedNet\n",
    "from logger import Logger\n",
    "from trainer_forJupyter import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODEL PARAMS\n",
    "model_params = {}\n",
    "model_params['save_dir'] = 'models/model_2/k_8/'\n",
    "# specify whether or not to use GPU (will set to False automatically if no GPU available)\n",
    "model_params['cuda'] = True\n",
    "# training data specifications\n",
    "model_params['k'] = 8 # depth or frequency bin indicator\n",
    "model_params['training_data_file']='train_data/json/phantom10mm.json'\n",
    "model_params['batch_size'] = 745\n",
    "# model architecture parameters\n",
    "model_params['input_dim'] = 130\n",
    "model_params['output_dim'] = 130\n",
    "model_params['layer_width'] = 784\n",
    "model_params['num_hidden'] = 4\n",
    "# model regularization parameters\n",
    "model_params['batch_norm_enable'] = 0\n",
    "model_params['data_noise_gaussian'] = 1\n",
    "model_params['dropout_input'] = 0.3\n",
    "model_params['dropout'] = 0.2\n",
    "# model weights \n",
    "model_params['save_initial'] = 0\n",
    "model_params['starting_weights'] = None \n",
    "# set loss function to 'L1Loss', 'MSELoss', or 'SmoothL1Loss'\n",
    "model_params['loss_function'] = 'SmoothL1Loss'\n",
    "# adam optimization parameters\n",
    "model_params['lr'] = 0.001\n",
    "model_params['beta1'] = 0.9\n",
    "model_params['beta2'] = 0.999\n",
    "model_params['weight_decay'] = 0\n",
    "# specify stopping criteria\n",
    "model_params['patience'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFY CUDA AVAILABILITY\n",
    "print('torch.cuda.is_available(): ' + str(torch.cuda.is_available()))\n",
    "if model_params['cuda'] and torch.cuda.is_available():\n",
    "    print('Using ' + str(torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    print('Not using CUDA')\n",
    "    model_params['cuda']=False\n",
    "device = torch.device(\"cuda:0\" if model_params['cuda'] else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IN THE 10MM DIAMETER PHYSICAL PHANTOM TRAINING DATA \n",
    "\n",
    "# load training data specification file\n",
    "with open(model_params['training_data_file'], 'r') as f:\n",
    "    data_json = json.load(f)\n",
    "\n",
    "# load primary training data\n",
    "dat_list = []\n",
    "for item in data_json['train']:\n",
    "    fname = item['file']\n",
    "    N = int( item['N'])\n",
    "    dat_list.append(ApertureDataset(fname,N,model_params['k'],0,0))\n",
    "dat_train = torch.utils.data.ConcatDataset(dat_list)\n",
    "\n",
    "# load eval training data (subset of primary training data)\n",
    "dat_list = []\n",
    "for item in data_json['train_eval']:\n",
    "    fname = item['file']\n",
    "    N = int( item['N'])\n",
    "    dat_list.append( ApertureDataset(fname,N,model_params['k'],0,0))\n",
    "dat_eval = torch.utils.data.ConcatDataset(dat_list)\n",
    "\n",
    "# load val data (separate validation set for computing stopping criteria)\n",
    "dat_list = []\n",
    "for item in data_json['val']:\n",
    "    fname = item['file']\n",
    "    N = int( item['N'])\n",
    "    dat_list.append( ApertureDataset(fname,N,model_params['k'],0,0))\n",
    "dat_val = torch.utils.data.ConcatDataset(dat_list)\n",
    "\n",
    "# setup data loaders\n",
    "last_batch_size = (len(dat_train) % model_params['batch_size'])\n",
    "last_batch_size = model_params['batch_size'] if (last_batch_size == 0) else last_batch_size\n",
    "print(f\"\\nLast batch size for train data: {last_batch_size}\\n\")\n",
    "drop_last = True if ( last_batch_size == 1) else False\n",
    "print(f\"Drop last batch: {drop_last}\")\n",
    "loader_train = torch.utils.data.DataLoader(dat_train, batch_size=model_params['batch_size'],\n",
    "                                            shuffle=True, num_workers=1, drop_last=drop_last)\n",
    "drop_last=False\n",
    "loader_train_eval = torch.utils.data.DataLoader(dat_eval, batch_size=len(dat_eval), \n",
    "                                            shuffle=False,num_workers=1,drop_last=drop_last)\n",
    "drop_last=False\n",
    "loader_val = torch.utils.data.DataLoader(dat_val, batch_size=len(dat_val), shuffle=False,\n",
    "                                                num_workers=1, drop_last=drop_last)\n",
    "\n",
    "# update model params to specify number of training examples\n",
    "model_params['num_samples_train'] = len(dat_train)\n",
    "model_params['num_samples_train_eval'] = len(dat_eval)\n",
    "model_params['num_samples_val'] = len(dat_val)\n",
    "model_params_path = os.path.join(model_params['save_dir'], 'model_params.txt')\n",
    "model_params['model_params_path'] = model_params_path\n",
    "if model_params['save_dir']:\n",
    "    ensure_dir(model_params['save_dir'])\n",
    "    save_model_params(model_params_path, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW TRAINING DATA EXAMPLES\n",
    "\n",
    "# get example accept region training data\n",
    "input_example_accept = dat_list[0][0][0]\n",
    "target_example_accept = dat_list[0][0][1]\n",
    "\n",
    "# get example reject region training data\n",
    "input_example_reject = dat_list[0][11][0]\n",
    "target_example_reject = dat_list[0][11][1]\n",
    "\n",
    "# set up subplot to show example training signals\n",
    "fig,axs = plt.subplots(nrows=2,ncols=2,sharey=True,sharex=True)\n",
    "\n",
    "# plot accept region signals\n",
    "input_plot_accept=axs[0,0].plot(input_example_accept)\n",
    "axs[0,0].set_title('INPUT')\n",
    "axs[0,0].set_ylabel('Normalized Amplitude')\n",
    "target_plot_accept=axs[0,1].plot(target_example_accept)\n",
    "axs[0,1].set_title('TARGET')\n",
    "\n",
    "# plot reject region signals\n",
    "input_plot_reject=axs[1,0].plot(input_example_reject)\n",
    "axs[1,0].set_ylabel('Normalized Amplitude')\n",
    "axs[1,0].set_xlabel('Channels')\n",
    "target_plot_reject=axs[1,1].plot(target_example_reject)\n",
    "axs[1,1].set_xlabel('Channels')\n",
    "\n",
    "# add colorbar and save figure\n",
    "fig.savefig(os.path.join(model_params['save_dir'],'example_training_data.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE THE MODEL\n",
    "model = FullyConnectedNet(input_dim=model_params['input_dim'],\n",
    "                                output_dim=model_params['output_dim'],\n",
    "                                layer_width=model_params['layer_width'],\n",
    "                                dropout=model_params['dropout'],\n",
    "                                dropout_input=model_params['dropout_input'],\n",
    "                                num_hidden=model_params['num_hidden'],\n",
    "                                starting_weights=model_params['starting_weights'],\n",
    "                                batch_norm_enable=model_params['batch_norm_enable'])\n",
    "model = model.to(device) # send to GPU if enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP LOSS FUNCTION AND OPTIMIZER\n",
    "\n",
    "# loss\n",
    "if model_params['loss_function'] == 'L1Loss':\n",
    "    loss = torch.nn.L1Loss()\n",
    "elif model_params['loss_function'] == 'MSELoss':\n",
    "    loss = torch.nn.MSELoss()\n",
    "elif model_params['loss_function'] == 'SmoothL1Loss':\n",
    "    loss = torch.nn.SmoothL1Loss()\n",
    "loss = loss.to(device) # send to GPU if enabled\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                lr=model_params['lr'],\n",
    "                                betas=(model_params['beta1'], model_params['beta2']),\n",
    "                                weight_decay=model_params['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "logger = Logger()\n",
    "trainer = Trainer(model=model,\n",
    "                        loss=loss,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=None,\n",
    "                        patience=model_params['patience'],\n",
    "                        loader_train=loader_train,\n",
    "                        loader_train_eval=loader_train_eval,\n",
    "                        loader_val=loader_val,\n",
    "                        cuda=model_params['cuda'],\n",
    "                        logger=logger,\n",
    "                        data_noise_gaussian=model_params['data_noise_gaussian'],\n",
    "                        save_dir=model_params['save_dir'])\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
